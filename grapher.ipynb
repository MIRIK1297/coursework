{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "data_dir = 'data/'\n",
    "prep_path = data_dir + 'preprocessed/'\n",
    "graphs_dir = prep_path + 'graphs/'\n",
    "\n",
    "prep_dirs = ['CuckooClean/', 'CuckooCleanHippo/', 'CuckooCleanPippo/', 'CuckooVirusShare/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert API calls sequences to bipartite graph representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_traces_num = 0\n",
    "processed_files_num = 0\n",
    "\n",
    "\n",
    "def process_log_file(prep_dir, filename, calls_encoding_map, args_encoding_map, args_counter):\n",
    "    global processed_traces_num\n",
    "    global processed_files_num\n",
    "    \n",
    "    filepath = prep_path + prep_dir + filename\n",
    "    with open(filepath) as json_file:\n",
    "        sample_logs = json.load(json_file)\n",
    "\n",
    "    for log_info in sample_logs:\n",
    "        g_calls = {}\n",
    "        g_args = {}\n",
    "        for call_info in log_info[\"calls\"]:\n",
    "            if len(call_info) != 1:\n",
    "                print('Log record {} len not 1 in {}'.format(str(call_info), filepath))\n",
    "                continue\n",
    "\n",
    "            call_name = next(iter(call_info))\n",
    "            call_args = call_info[call_name]\n",
    "\n",
    "            if not call_name in calls_encoding_map:\n",
    "                calls_encoding_map[call_name] = len(calls_encoding_map)\n",
    "\n",
    "            call_code = calls_encoding_map[call_name]\n",
    "\n",
    "            if not call_code in g_calls:\n",
    "                g_calls[call_code] = set()\n",
    "\n",
    "            for call_arg in call_args:\n",
    "                str_arg = str(call_arg)\n",
    "\n",
    "                if not str_arg in args_encoding_map:\n",
    "                    args_encoding_map[str_arg] = len(args_encoding_map)\n",
    "\n",
    "                arg_code = args_encoding_map[str_arg]\n",
    "                g_calls[call_code].add(arg_code)\n",
    "\n",
    "                if not arg_code in g_args:\n",
    "                    g_args[arg_code] = set()\n",
    "                g_args[arg_code].add(call_code)\n",
    "\n",
    "                args_counter[arg_code] = args_counter.get(arg_code, 0) + 1\n",
    "\n",
    "        graph = {'g_calls' : g_calls, 'g_args' : g_args}\n",
    "        with open(graphs_dir + prep_dir + str(processed_traces_num) + '.pkl', 'wb') as out_file:\n",
    "            pickle.dump(graph, out_file, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        processed_traces_num += 1\n",
    "            \n",
    "    processed_files_num += 1\n",
    "        \n",
    "        \n",
    "def process_all_logs():\n",
    "    #map string names with unique numbers\n",
    "    calls_encoding_map = {}\n",
    "    args_encoding_map = {}\n",
    "    args_counter = {}\n",
    "    for prep_dir in prep_dirs:\n",
    "        print('Processing ' + prep_path + prep_dir)\n",
    "        if not os.path.exists(graphs_dir + prep_dir):\n",
    "            os.makedirs(graphs_dir + prep_dir)\n",
    "\n",
    "        for filename in tqdm(sorted([x for x in os.listdir(prep_path + prep_dir) if x.endswith('.json')])):            \n",
    "            process_log_file(prep_dir, filename, calls_encoding_map, args_encoding_map, args_counter)\n",
    "                \n",
    "    with open(graphs_dir  + 'calls_encoding_map.pkl', 'wb') as out_file:\n",
    "        pickle.dump(calls_encoding_map, out_file, pickle.HIGHEST_PROTOCOL)     \n",
    "    print('calls_encoding_map written')\n",
    "    calls_encoding_map = {}\n",
    "\n",
    "    with open(graphs_dir + 'args_counter.pkl', 'wb') as out_file:\n",
    "        pickle.dump(args_counter, out_file, pickle.HIGHEST_PROTOCOL)        \n",
    "    print('args_counter written')\n",
    "    args_counter = {}\n",
    "\n",
    "    with open(graphs_dir + 'args_encoding_map.pkl', 'wb') as out_file:\n",
    "        pickle.dump(args_encoding_map, out_file, pickle.HIGHEST_PROTOCOL)        \n",
    "    print('args_encoding_map written')\n",
    "    args_encoding_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(graphs_dir + 'calls_encoding_map.pkl', 'rb') as in_file:\n",
    "    unique_calls_num = len(pickle.load(in_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take most frequent arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_unique_args_num = 2**13 #8192\n",
    "with open(graphs_dir + 'top_unique_args_position_map_' + str(top_unique_args_num) + '.pkl', 'rb') as out_file:\n",
    "    top_unique_args_position_map = pickle.load(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(graphs_dir + 'args_counter.pkl', 'rb') as in_file:\n",
    "    args_counter = pickle.load(in_file)\n",
    "    \n",
    "sorted_args = sorted(args_counter, key=args_counter.get, reverse=True)\n",
    "top_unique_args_position_map = {arg : i + unique_calls_num for i, arg in enumerate(sorted_args[:top_unique_args_num])}\n",
    "with open(graphs_dir + 'top_unique_args_position_map_' + str(top_unique_args_num) + '.pkl', 'wb') as out_file:\n",
    "    pickle.dump(top_unique_args_position_map, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract behavior patterns from graphs and convert to binary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_vectors_size = unique_calls_num + top_unique_args_num\n",
    "\n",
    "binary_path = prep_path + '8477_vec_size/binary/'\n",
    "train_path = binary_path + 'train/'\n",
    "test_path = binary_path + 'test/'\n",
    "benign_dir = 'benign/'\n",
    "malicious_dir = 'malicious/'\n",
    "\n",
    "if not os.path.exists(train_path + benign_dir):\n",
    "    os.makedirs(train_path + benign_dir)\n",
    "    \n",
    "if not os.path.exists(train_path + malicious_dir):\n",
    "    os.makedirs(train_path + malicious_dir)\n",
    "    \n",
    "if not os.path.exists(test_path + benign_dir):\n",
    "    os.makedirs(test_path + benign_dir)\n",
    "    \n",
    "if not os.path.exists(test_path + malicious_dir):\n",
    "    os.makedirs(test_path + malicious_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_of_graphs():\n",
    "    nums_in_dirs = [len([x for x in os.listdir(graphs_dir + prep_dir) if x.endswith('.pkl')]) for prep_dir in prep_dirs]\n",
    "    return sum(nums_in_dirs)\n",
    "\n",
    "\n",
    "def extract_behavior_patterns(g_calls, g_args):\n",
    "    global top_unique_args_position_map\n",
    "    if len(g_args) == 0:\n",
    "        return [(set([call_name]), set()) for call_name in g_calls.keys()]\n",
    "    \n",
    "    result = []                \n",
    "    max_arg_degree = max([len(calls_set) for calls_set in g_args.values()])\n",
    "    for i in range(1, max_arg_degree + 1):\n",
    "        for arg in [k for k, v in g_args.items() if len(v) == i]:\n",
    "            pattern_calls = g_args[arg].copy()\n",
    "            pattern_args = set()\n",
    "            if arg in top_unique_args_position_map:\n",
    "                pattern_args.add(arg)\n",
    "                \n",
    "            args_candidates = g_calls[next(iter(pattern_calls))]\n",
    "            for arg_candidate in args_candidates:\n",
    "                if arg_candidate in top_unique_args_position_map and all([arg_candidate in g_calls[call] for call in pattern_calls]):\n",
    "                    pattern_args.add(arg_candidate)\n",
    "                    \n",
    "            if not any([pattern_calls == p_calls and pattern_args == p_args for p_calls, p_args in result]):\n",
    "                result.append((pattern_calls, pattern_args))\n",
    "    \n",
    "    for call_name in [k for k, v in g_calls.items() if len(v) == 0]:\n",
    "        result.append((set([call_name]), set()))\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def behavior_patterns_to_binary_vectors(nb_patterns):\n",
    "    global top_unique_args_position_map\n",
    "    \n",
    "    result = []\n",
    "    for pattern_calls, pattern_args in nb_patterns:\n",
    "        binary_pattern = np.zeros((binary_vectors_size,), dtype=np.byte)\n",
    "        \n",
    "        for p_call in pattern_calls:\n",
    "            binary_pattern[p_call] = 1\n",
    "            if p_call in top_unique_args_position_map.values():\n",
    "                print('ggwp')\n",
    "        \n",
    "        for p_arg in pattern_args:\n",
    "            binary_pattern[top_unique_args_position_map[p_arg]] = 1\n",
    "                \n",
    "        result.append(binary_pattern)\n",
    "        \n",
    "    return np.stack(result)\n",
    "\n",
    "\n",
    "def process_graphs_to_bin_vectors_dataset():\n",
    "    processed_count = 0\n",
    "    num_of_graphs = get_num_of_graphs()\n",
    "\n",
    "    indices = np.random.permutation(num_of_graphs)\n",
    "    train_size = len(indices) * 8 // 10\n",
    "    inds_train = indices[:train_size]\n",
    "    inds_test = indices[train_size:]\n",
    "    \n",
    "    \n",
    "    for prep_dir in prep_dirs:\n",
    "        print('Processing {}'.format(graphs_dir + prep_dir))\n",
    "        filenames = sorted([x for x in os.listdir(graphs_dir + prep_dir) if x.endswith('.pkl')])\n",
    "        for filename in tqdm(filenames):\n",
    "            with open(graphs_dir + prep_dir + filename, 'rb') as in_file:\n",
    "                sample_graph = pickle.load(in_file)\n",
    "                \n",
    "            behavior_patterns = extract_behavior_patterns(sample_graph['g_calls'], sample_graph['g_args'])\n",
    "            bin_patterns = behavior_patterns_to_binary_vectors(behavior_patterns)\n",
    "            \n",
    "            save_path = train_path if processed_count in inds_train else test_path\n",
    "            save_path += malicious_dir if prep_dir == 'CuckooVirusShare/' else benign_dir\n",
    "            save_path += str(processed_count) + '.npy'\n",
    "            np.save(save_path, bin_patterns)\n",
    "            processed_count += 1\n",
    "    print(processed_count, num_of_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/preprocessed/graphs/CuckooClean/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b0f1d048fe4d198563f4f0b3997de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data/preprocessed/graphs/CuckooCleanHippo/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020d1f01df5b45d1814010a65e5af9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1357.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data/preprocessed/graphs/CuckooCleanPippo/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0699abdafce4417b9d4b7602d3b0c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=252.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data/preprocessed/graphs/CuckooVirusShare/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d353d48ccd48149aeef8c902122cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2026.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4740 4740\n"
     ]
    }
   ],
   "source": [
    "process_graphs_to_bin_vectors_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
